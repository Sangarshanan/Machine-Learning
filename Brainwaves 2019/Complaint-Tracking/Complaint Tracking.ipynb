{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complaint Status Tracking (HACKEREARTH CHALLENGE)\n",
    "\n",
    "Problem Statement\n",
    "\n",
    "Societe Generale (SocGen) is a French multinational banking and financial services company. With over 1,54,000 employees, based in 76 countries, they handle over 32 million clients throughout the world on a daily basis.\n",
    "\n",
    "They provide services like retail banking, corporate and investment banking, asset management, portfolio management, insurance and other financial services.\n",
    "\n",
    "While handling customer complaints, it is hard to track the status of the complaint. To automate this process, SocGen wants you to build a model that can automatically predict the complaint status (how the complaint was resolved) based on the complaint submitted by the consumer and other related meta-data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import math\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample= pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Complaint-ID</th>\n",
       "      <th>Date-received</th>\n",
       "      <th>Transaction-Type</th>\n",
       "      <th>Complaint-reason</th>\n",
       "      <th>Company-response</th>\n",
       "      <th>Date-sent-to-company</th>\n",
       "      <th>Complaint-Status</th>\n",
       "      <th>Consumer-disputes</th>\n",
       "      <th>Consumer-complaint-summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tr-1</td>\n",
       "      <td>11/11/2015</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Loan servicing, payments, escrow account</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/11/2015</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Seterus, Inc a déposé un faux rapport auprès d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tr-2</td>\n",
       "      <td>7/7/2015</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Incorrect information on credit report</td>\n",
       "      <td>Company chooses not to provide a public response</td>\n",
       "      <td>7/7/2015</td>\n",
       "      <td>Closed with non-monetary relief</td>\n",
       "      <td>No</td>\n",
       "      <td>XX / XX / XXXX La requête en faillite n ° XXXX...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tr-3</td>\n",
       "      <td>5/7/2015</td>\n",
       "      <td>Bank account or service</td>\n",
       "      <td>Using a debit or ATM card</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5/7/2015</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>No</td>\n",
       "      <td>El XXXX / XXXX / 15, estaba preparando el vuel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tr-4</td>\n",
       "      <td>11/12/2016</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Cont'd attempts collect debt not owed</td>\n",
       "      <td>Company believes it acted appropriately as aut...</td>\n",
       "      <td>11/12/2016</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>No</td>\n",
       "      <td>The loan was paid in XXXX XXXX. In XXXX, 4 yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tr-5</td>\n",
       "      <td>9/29/2016</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>Payoff process</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>9/29/2016</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>No</td>\n",
       "      <td>J'ai obtenu un compte de crédit de soins pour ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Complaint-ID Date-received         Transaction-Type  \\\n",
       "0         Tr-1    11/11/2015                 Mortgage   \n",
       "1         Tr-2      7/7/2015         Credit reporting   \n",
       "2         Tr-3      5/7/2015  Bank account or service   \n",
       "3         Tr-4    11/12/2016          Debt collection   \n",
       "4         Tr-5     9/29/2016              Credit card   \n",
       "\n",
       "                           Complaint-reason  \\\n",
       "0  Loan servicing, payments, escrow account   \n",
       "1    Incorrect information on credit report   \n",
       "2                 Using a debit or ATM card   \n",
       "3     Cont'd attempts collect debt not owed   \n",
       "4                            Payoff process   \n",
       "\n",
       "                                    Company-response Date-sent-to-company  \\\n",
       "0                                                NaN           11/11/2015   \n",
       "1   Company chooses not to provide a public response             7/7/2015   \n",
       "2                                                NaN             5/7/2015   \n",
       "3  Company believes it acted appropriately as aut...           11/12/2016   \n",
       "4  Company has responded to the consumer and the ...            9/29/2016   \n",
       "\n",
       "                  Complaint-Status Consumer-disputes  \\\n",
       "0          Closed with explanation               Yes   \n",
       "1  Closed with non-monetary relief                No   \n",
       "2          Closed with explanation                No   \n",
       "3          Closed with explanation                No   \n",
       "4          Closed with explanation                No   \n",
       "\n",
       "                          Consumer-complaint-summary  \n",
       "0  Seterus, Inc a déposé un faux rapport auprès d...  \n",
       "1  XX / XX / XXXX La requête en faillite n ° XXXX...  \n",
       "2  El XXXX / XXXX / 15, estaba preparando el vuel...  \n",
       "3  The loan was paid in XXXX XXXX. In XXXX, 4 yea...  \n",
       "4  J'ai obtenu un compte de crédit de soins pour ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have to Predict the Complaint Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Closed with explanation            34300\n",
       "Closed with non-monetary relief     5018\n",
       "Closed with monetary relief         2818\n",
       "Closed                               809\n",
       "Untimely response                    321\n",
       "Name: Complaint-Status, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Complaint-Status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complaint ID is irrelevant to the Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('Complaint-ID',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CREATE A COPY OF DATAFRAME FOR LABEL ENCODING \n",
    "\n",
    "df_label = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11/11/2015'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train['Date-received'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CONVERT STRING TO DATETIME FORMAT\n",
    "\n",
    "#for i in range(0,len(train)):\n",
    "    #df_label['Date-received'][i] = datetime.strptime(train['Date-received'][i],'%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding of Categorical variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NAIVE METHOD BY DROPPING ALL DATETIME COLUMNS (THEY MIGHT BE IMPORTANT...WE WILL CHECK LATER)\n",
    "\n",
    "df_label = df_label.drop('Date-received',axis=1)\n",
    "df_label = df_label.drop('Date-sent-to-company',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LET US ALSO DROP THE DESCRIPTION COLUMN (NEED NLP THAT WE MIGHT IGNORE FOR NAIVE APPROACH)\n",
    "\n",
    "df_label = df_label.drop('Consumer-complaint-summary',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are several Null values so Let us replace those with \"NO RESPONSE\" & \"NOT KNOWN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22506\n",
      "7698\n"
     ]
    }
   ],
   "source": [
    "print(df_label['Company-response'].isnull().sum())\n",
    "print(df_label['Consumer-disputes'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label['Company-response'] = df_label['Company-response'].fillna('No Response')\n",
    "df_label['Consumer-disputes'] = df_label['Consumer-disputes'].fillna('Not Known')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df_label['Company-response'].isnull().sum())\n",
    "print(df_label['Consumer-disputes'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = preprocessing.LabelEncoder()\n",
    "tt = tt.fit(df_label['Transaction-Type'])\n",
    "cr = preprocessing.LabelEncoder()\n",
    "cr = cr.fit(df_label['Complaint-reason'])\n",
    "cre = preprocessing.LabelEncoder()\n",
    "cre = cre.fit(df_label['Company-response'])\n",
    "cd = preprocessing.LabelEncoder()\n",
    "cd = cd.fit(df_label['Consumer-disputes'])\n",
    "cs= preprocessing.LabelEncoder()\n",
    "cs = cs.fit(df_label['Complaint-Status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converted all categorical variables so the dataframe is algorithm ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label['Transaction-Type'] = tt.transform(df_label['Transaction-Type'])\n",
    "df_label['Complaint-reason'] = cr.transform(df_label['Complaint-reason'])\n",
    "df_label['Company-response'] = cre.transform(df_label['Company-response'])\n",
    "df_label['Consumer-disputes'] = cd.transform(df_label['Consumer-disputes'])\n",
    "df_label['Complaint-Status'] = cs.transform(df_label['Complaint-Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction-Type</th>\n",
       "      <th>Complaint-reason</th>\n",
       "      <th>Company-response</th>\n",
       "      <th>Complaint-Status</th>\n",
       "      <th>Consumer-disputes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>78</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Transaction-Type  Complaint-reason  Company-response  Complaint-Status  \\\n",
       "0                10                78                10                 1   \n",
       "\n",
       "   Consumer-disputes  \n",
       "0                  2  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_label['Complaint-Status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split and applying Algorithms for NAIVE LABEL ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_label.drop('Complaint-Status',axis=1), \n",
    "                 df_label['Complaint-Status'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 SCORE for Naive Bayes: 0.5197088275842644\n",
      "F1 SCORE for Logistic Regression: 0.7019842327760217\n",
      "F1 SCORE For Decision Trees: 0.7198656879561207\n",
      "F1 SCORE for KNN: 0.7206302352354023\n",
      "F1 SCORE for Random Forest: 0.7208757103057245\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "prediction=nb.predict(X_test)\n",
    "print(\"F1 SCORE for Naive Bayes:\",metrics.f1_score(y_test, prediction, average='weighted'))\n",
    "\n",
    "clf = LogisticRegression(random_state=0, multi_class='ovr')\n",
    "model = clf.fit(X_train, y_train)\n",
    "prediction=model.predict(X_test)\n",
    "print(\"F1 SCORE for Logistic Regression:\",metrics.f1_score(y_test, prediction, average='weighted'))\n",
    "\n",
    "decisiontree=DecisionTreeClassifier()\n",
    "decisiontree.fit(X_train, y_train)\n",
    "prediction=decisiontree.predict(X_test)\n",
    "print(\"F1 SCORE For Decision Trees:\",metrics.f1_score(y_test, prediction, average='weighted'))\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(X_train, y_train)\n",
    "prediction=neigh.predict(X_test)\n",
    "print(\"F1 SCORE for KNN:\",metrics.f1_score(y_test, prediction, average='weighted'))\n",
    "\n",
    "randomforest=RandomForestClassifier(n_estimators =100)\n",
    "randomforest.fit(X_train, y_train)\n",
    "prediction=randomforest.predict(X_test)\n",
    "print(\"F1 SCORE for Random Forest:\",metrics.f1_score(y_test, prediction, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Transaction-Type',\n",
       "  'Complaint-reason',\n",
       "  'Company-response',\n",
       "  'Consumer-disputes'],\n",
       " [0.3585601473414549,\n",
       "  0.375994951593255,\n",
       "  0.1893296666155011,\n",
       "  0.07611523444978911])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(X_train.columns), list(randomforest.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Company response and Company disputes have the lowest importance (Maybe cause of the NAN values that were there)\n",
    "- Highly dependent on the Complaint reason and the Transaction Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us do some Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('11/11/2015', '11/11/2015')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Date-received'][0] ,train['Date-sent-to-company'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date received and Date sent to company can be either\n",
    "\n",
    "- Same \n",
    "- DIfferent\n",
    "\n",
    "Let us generate a new column based on that data and call it Promptness in customer service = Yes or No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label['Promptness'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(train)):\n",
    "    if(train['Date-received'][i] != train['Date-sent-to-company'][i]):\n",
    "        df_label['Promptness'][i] = 0\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction-Type</th>\n",
       "      <th>Complaint-reason</th>\n",
       "      <th>Company-response</th>\n",
       "      <th>Complaint-Status</th>\n",
       "      <th>Consumer-disputes</th>\n",
       "      <th>Promptness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>78</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Transaction-Type  Complaint-reason  Company-response  Complaint-Status  \\\n",
       "0                10                78                10                 1   \n",
       "\n",
       "   Consumer-disputes  Promptness  \n",
       "0                  2           1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take calculate the correlation for this new feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transaction-Type    -0.115914\n",
       "Complaint-reason    -0.002027\n",
       "Company-response    -0.005819\n",
       "Complaint-Status     1.000000\n",
       "Consumer-disputes   -0.109791\n",
       "Promptness           0.006972\n",
       "Name: Complaint-Status, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.corr()['Complaint-Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 SCORE for Naive Bayes: 0.5213423790556663\n",
      "F1 SCORE for Logistic Regression: 0.7019842327760217\n",
      "F1 SCORE For Decision Trees: 0.7214784119910971\n",
      "F1 SCORE for KNN: 0.7215723534275794\n",
      "F1 SCORE for Random Forest: 0.7211507527573842\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_label.drop('Complaint-Status',axis=1), \n",
    "                 df_label['Complaint-Status'], test_size=0.33, random_state=42)\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "prediction=nb.predict(X_test)\n",
    "print(\"F1 SCORE for Naive Bayes:\",metrics.f1_score(y_test, prediction, average='weighted'))\n",
    "\n",
    "clf = LogisticRegression(random_state=0, multi_class='ovr')\n",
    "model = clf.fit(X_train, y_train)\n",
    "prediction=model.predict(X_test)\n",
    "print(\"F1 SCORE for Logistic Regression:\",metrics.f1_score(y_test, prediction, average='weighted'))\n",
    "\n",
    "decisiontree=DecisionTreeClassifier()\n",
    "decisiontree.fit(X_train, y_train)\n",
    "prediction=decisiontree.predict(X_test)\n",
    "print(\"F1 SCORE For Decision Trees:\",metrics.f1_score(y_test, prediction, average='weighted'))\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(X_train, y_train)\n",
    "prediction=neigh.predict(X_test)\n",
    "print(\"F1 SCORE for KNN:\",metrics.f1_score(y_test, prediction, average='weighted'))\n",
    "\n",
    "randomforest=RandomForestClassifier(n_estimators =100)\n",
    "randomforest.fit(X_train, y_train)\n",
    "prediction=randomforest.predict(X_test)\n",
    "print(\"F1 SCORE for Random Forest:\",metrics.f1_score(y_test, prediction, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for SVM kernel is 0.792968202829528\n",
      "Accuracy for SVM kernel is 0.7933884297520661\n"
     ]
    }
   ],
   "source": [
    "types=['rbf','linear']\n",
    "for i in types:\n",
    "    model=svm.SVC(kernel=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    prediction=model.predict(X_test)\n",
    "    print('Accuracy for SVM kernel is',metrics.accuracy_score(prediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have a Slight increase in accuracy\n",
    "\n",
    "### This might not seem like much but it shows us how powerful feature engineering is as a Machine learning tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets look at COMPLAINT REASON column as it has >70 unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Incorrect information on credit report',\n",
       " 'Incorrect information on your report')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Complaint-reason'].value_counts().keys()[0] , train['Complaint-reason'].value_counts().keys()[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Both essentially mean almost the same thing (But label encoder seperates them )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reason = list(train['Complaint-reason'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni = list(train['Complaint-reason'].value_counts().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Incorrect information on credit report',\n",
       " \"Cont'd attempts collect debt not owed\",\n",
       " 'Loan servicing, payments, escrow account',\n",
       " 'Loan modification,collection,foreclosure',\n",
       " 'Dealing with my lender or servicer',\n",
       " 'Disclosure verification of debt',\n",
       " 'Incorrect information on your report',\n",
       " 'Communication tactics',\n",
       " 'Account opening, closing, or management',\n",
       " \"Credit reporting company's investigation\"]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert each sentence with its corresponding TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = []\n",
    "for i in uni:\n",
    "    kk = i.split(' ')\n",
    "    kk = [j.lower() for j in kk]\n",
    "    e.extend(kk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43266, 700)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(k), len(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [i.lower() for i in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loan servicing, payments, escrow account'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = ' '.join(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(lis,elem):\n",
    "    no = lis.count(elem)\n",
    "    return no/len(lis)\n",
    "\n",
    "def idf(k,e,elem):\n",
    "    count = 0\n",
    "    n = len(k)\n",
    "    for i in k:\n",
    "        if elem in i:\n",
    "            count+=1\n",
    "    return 1+ math.log10(len(k)/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "TF=[]\n",
    "IDF = []\n",
    "e = list(set(e))\n",
    "for i in e:\n",
    "    TF.append(tf(elements,i))\n",
    "    IDF.append(idf(k,e,i))\n",
    "T = pd.Series(TF)\n",
    "W = pd.Series(e)\n",
    "I = pd.Series(IDF)\n",
    "df['Words'] = W.values\n",
    "df['TF'] = T.values\n",
    "df['IDF'] = I.values\n",
    "df['TFIDF'] = df['TF'] * df['IDF']\n",
    "tfidf = pd.Series(df.TFIDF.values,index=df.Words).to_dict()\n",
    "mat = []\n",
    "for i in k:\n",
    "    wor = i.split(' ')\n",
    "    el=[]\n",
    "    for j in e:\n",
    "        if j in wor:\n",
    "            el.append(tfidf[j])\n",
    "        else:\n",
    "            el.append(0)\n",
    "    mat.append(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mat) == len(df_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = [sum(i)/len(i) for i in mat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label['reason'] = tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction-Type</th>\n",
       "      <th>Complaint-reason</th>\n",
       "      <th>Company-response</th>\n",
       "      <th>Complaint-Status</th>\n",
       "      <th>Consumer-disputes</th>\n",
       "      <th>Promptness</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>78</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Transaction-Type  Complaint-reason  Company-response  Complaint-Status  \\\n",
       "0                10                78                10                 1   \n",
       "\n",
       "   Consumer-disputes  Promptness    reason  \n",
       "0                  2           1  0.000122  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = df_label.drop('Complaint-reason',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets apply the algorithms after generating tfidf features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 SCORE for Naive Bayes: 0.5188888132715702\n",
      "F1 SCORE for Logistic Regression: 0.7019842327760217\n",
      "F1 SCORE For Decision Trees: 0.7215626388691304\n",
      "F1 SCORE for KNN: 0.7231281072749107\n",
      "F1 SCORE for Random Forest: 0.7213825646306306\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_label.drop('Complaint-Status',axis=1), \n",
    "                 df_label['Complaint-Status'], test_size=0.33, random_state=42)\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "prediction=nb.predict(X_test)\n",
    "print(\"F1 SCORE for Naive Bayes:\",metrics.f1_score(y_test, prediction, average='weighted'))\n",
    "\n",
    "clf = LogisticRegression(random_state=0, multi_class='ovr')\n",
    "model = clf.fit(X_train, y_train)\n",
    "prediction=model.predict(X_test)\n",
    "print(\"F1 SCORE for Logistic Regression:\",metrics.f1_score(y_test, prediction, average='weighted'))\n",
    "\n",
    "decisiontree=DecisionTreeClassifier()\n",
    "decisiontree.fit(X_train, y_train)\n",
    "prediction=decisiontree.predict(X_test)\n",
    "print(\"F1 SCORE For Decision Trees:\",metrics.f1_score(y_test, prediction, average='weighted'))\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "neigh.fit(X_train, y_train)\n",
    "prediction=neigh.predict(X_test)\n",
    "print(\"F1 SCORE for KNN:\",metrics.f1_score(y_test, prediction, average='weighted'))\n",
    "\n",
    "randomforest=RandomForestClassifier(n_estimators =100)\n",
    "randomforest.fit(X_train, y_train)\n",
    "prediction=randomforest.predict(X_test)\n",
    "print(\"F1 SCORE for Random Forest:\",metrics.f1_score(y_test, prediction, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again a very slight change in F1 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for SVM kernel is 0.7935985432133352\n"
     ]
    }
   ],
   "source": [
    "types=['rbf']\n",
    "for i in types:\n",
    "    model=svm.SVC(kernel=i)\n",
    "    model.fit(X_train, y_train)\n",
    "    prediction=model.predict(X_test)\n",
    "    print('Accuracy for SVM kernel is',metrics.accuracy_score(prediction,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "idval = test['Complaint-ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop('Complaint-ID',axis=1)\n",
    "test = test.drop('Consumer-complaint-summary',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = test['Complaint-reason']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop('Complaint-reason',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Company-response'] = test['Company-response'].fillna('No Response')\n",
    "test['Consumer-disputes'] = test['Consumer-disputes'].fillna('Not Known')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Transaction-Type'] = tt.transform(test['Transaction-Type'])\n",
    "test['Company-response'] = cre.transform(test['Company-response'])\n",
    "test['Consumer-disputes'] = cd.transform(test['Consumer-disputes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Promptness'] = 1\n",
    "for i in range(0,len(test)):\n",
    "    if(test['Date-received'][i] != test['Date-sent-to-company'][i]):\n",
    "        test['Promptness'][i] = 0\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(['Date-received','Date-sent-to-company'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Complaint-reason'] = r\n",
    "reason = list(test['Complaint-reason'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni = list(test['Complaint-reason'].value_counts().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Incorrect information on credit report',\n",
       " \"Cont'd attempts collect debt not owed\",\n",
       " 'Loan servicing, payments, escrow account',\n",
       " 'Loan modification,collection,foreclosure',\n",
       " 'Incorrect information on your report',\n",
       " 'Dealing with my lender or servicer',\n",
       " 'Disclosure verification of debt',\n",
       " 'Communication tactics',\n",
       " 'Account opening, closing, or management',\n",
       " \"Credit reporting company's investigation\"]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = []\n",
    "for i in uni:\n",
    "    kk = i.split(' ')\n",
    "    kk = [j.lower() for j in kk]\n",
    "    e.extend(kk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18543, 689)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(k), len(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [i.lower() for i in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'account opening, closing, or management'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = ' '.join(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(lis,elem):\n",
    "    no = lis.count(elem)\n",
    "    return no/len(lis)\n",
    "\n",
    "def idf(k,e,elem):\n",
    "    count = 0\n",
    "    n = len(k)\n",
    "    for i in k:\n",
    "        if elem in i:\n",
    "            count+=1\n",
    "    return 1+ math.log10(len(k)/count)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "TF=[]\n",
    "IDF = []\n",
    "e = list(set(e))\n",
    "for i in e:\n",
    "    TF.append(tf(elements,i))\n",
    "    IDF.append(idf(k,e,i))\n",
    "T = pd.Series(TF)\n",
    "W = pd.Series(e)\n",
    "I = pd.Series(IDF)\n",
    "df['Words'] = W.values\n",
    "df['TF'] = T.values\n",
    "df['IDF'] = I.values\n",
    "df['TFIDF'] = df['TF'] * df['IDF']\n",
    "tfidf = pd.Series(df.TFIDF.values,index=df.Words).to_dict()\n",
    "mat = []\n",
    "for i in k:\n",
    "    wor = i.split(' ')\n",
    "    el=[]\n",
    "    for j in e:\n",
    "        if j in wor:\n",
    "            el.append(tfidf[j])\n",
    "        else:\n",
    "            el.append(0)\n",
    "    mat.append(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mat) == len(test)\n",
    "tfidf = [sum(i)/len(i) for i in mat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['reason'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test['reason'])  = tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.drop('Complaint-reason',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = cs.inverse_transform(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Complaint-Status'] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Closed with explanation        18450\n",
       "Closed with monetary relief       93\n",
       "Name: Complaint-Status, dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Complaint-Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test.drop(['Transaction-Type','Company-response','Consumer-disputes','Promptness','reason'],axis=1)\n",
    "t['Complaint-ID'] = idval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsTitles=[\"Complaint-ID\",\"Complaint-Status\"]\n",
    "df=t.reindex(columns=columnsTitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Closed with explanation        18450\n",
       "Closed with monetary relief       93\n",
       "Name: Complaint-Status, dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Complaint-Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
